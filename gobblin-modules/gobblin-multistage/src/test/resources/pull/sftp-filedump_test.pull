job.name=testFileDumpJob

source.class=org.apache.gobblin.org.apache.gobblin.multistage.source.SftpSource
source.conn.username=LinkedIn
source.conn.host=ftp.test.com
source.conn.private.key=/src/test/resources/key/test_private_key
source.conn.port=22
source.conn.timeout=500000

ms.extractor.class=org.apache.gobblin.org.apache.gobblin.multistage.extractor.CsvExtractor
ms.http.client.factory=org.apache.gobblin.org.apache.gobblin.multistage.factory.SftpClientFactory
ms.output.schema=[{"columnName":"col1","comment":"","isNullable":"true","dataType":{"type":"string"}},{"columnName":"col2","comment":"","isNullable":"false","dataType":{"type":"timestamp"}}}]
ms.secondary.input=[{"path": "/tmp/gobblin/job-output/test_metadata/part.task_testFileListJob_1592805229961_0_0.avro", "fields": ["fileName"]}]
ms.work.unit.parallelism.max=50
ms.source.uri={{fileName}}
ms.extractor.target.file.name=test_ingestion
ms.csv.separator=|
ms.csv.quote.character=\u0000

extract.namespace=test
extract.table.name=test_ingestion
extract.table.type=SNAPSHOT_ONLY
extract.is.full=true

state.store.type=fs
fs.uri=file://localhost/
state.store.fs.uri=file://localhost/
data.publisher.final.dir=/tmp/gobblin/job-output/${extract.table.name}

writer.destination.type=HDFS
writer.output.format=AVRO

sftpConn.timeout=60000
converter.classes=org.apache.gobblin.converter.csv.CsvToJsonConverterV2,org.apache.gobblin.converter.avro.JsonIntermediateToAvroConverter